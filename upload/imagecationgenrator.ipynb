{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d683f96e-99df-4998-88fb-2b26a8499826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned CSV saved as: ./archive/flickr30k_images/results_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"./archive/flickr30k_images/results.csv\"\n",
    "output_file = \"./archive/flickr30k_images/results_cleaned.csv\"\n",
    "\n",
    "# Try flexible parsing and skip bad lines\n",
    "data = pd.read_csv(\n",
    "    input_file,\n",
    "    sep='|',\n",
    "    engine='python',\n",
    "    skipinitialspace=True,\n",
    "    on_bad_lines='skip',   # ✅ skip malformed lines\n",
    "    quoting=3              # ✅ disable quote handling issues\n",
    ")\n",
    "\n",
    "# Remove unwanted spaces\n",
    "data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Fix column names if needed\n",
    "data.columns = ['image_name', 'comment_number', 'comment'][:len(data.columns)]\n",
    "\n",
    "# Drop rows missing important values\n",
    "data.dropna(subset=['image_name', 'comment'], inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save cleaned file\n",
    "data.to_csv(output_file, index=False)\n",
    "print(\"✅ Cleaned CSV saved as:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8897098-d35f-4391-af24-ebc594c4bbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79821821-ce38-4cce-9cee-08668db3d94f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb8d07b-f060-4595-96cc-47509123d978",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25560\\1389388749.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaption\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"off\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;31m# Display sample images with captions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mdisplay_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;31m# Text preprocessing function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtext_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25560\\1389388749.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(temp_df)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33m../input/flickr8k/Images/\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaption\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"off\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'image'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Dense, LSTM, Embedding, Dropout, \n",
    "                                    concatenate, Reshape, add, GlobalAveragePooling2D)\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textwrap import wrap\n",
    "import warnings\n",
    "\n",
    "# Set visualization parameters\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"dark\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Data Loading and Preprocessing\n",
    "# =================================\n",
    "\n",
    "# Define image path and load captions\n",
    "image_path = './archive/flickr30k_images'\n",
    "data = pd.read_csv(\"./archive/flickr30k_images/results_cleaned.csv\", sep=None, engine='python')\n",
    "\n",
    "# Function to read and preprocess images\n",
    "def readImage(path, img_size=224):\n",
    "    img = load_img(path, color_mode='rgb', target_size=(img_size, img_size))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0  # Normalize to [0,1]\n",
    "    return img\n",
    "\n",
    "# Function to display images with captions\n",
    "def display_images(temp_df):\n",
    "    temp_df = temp_df.reset_index(drop=True)\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    n = 0\n",
    "    for i in range(15):\n",
    "        n += 1\n",
    "        plt.subplot(5, 5, n)\n",
    "        plt.subplots_adjust(hspace=0.7, wspace=0.3)\n",
    "        image = readImage(f\"../input/flickr8k/Images/{temp_df.image[i]}\")\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"\\n\".join(wrap(temp_df.caption[i], 20)))\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "# Display sample images with captions\n",
    "display_images(data.sample(15))\n",
    "\n",
    "# Text preprocessing function\n",
    "def text_preprocessing(data):\n",
    "    # Convert to lowercase\n",
    "    data['caption'] = data['caption'].str.lower()\n",
    "    # Remove non-alphabet characters\n",
    "    data['caption'] = data['caption'].str.replace(\"[^A-Za-z]\", \"\", regex=True)\n",
    "    # Remove extra spaces\n",
    "    data['caption'] = data['caption'].str.replace(\"\\s+\", \" \", regex=True)\n",
    "    # Remove single characters\n",
    "    data['caption'] = data['caption'].apply(lambda x: \" \".join([word for word in x.split() if len(word) > 1]))\n",
    "    # Add start and end tokens\n",
    "    data['caption'] = \"startseq \" + data['caption'] + \" endseq\"\n",
    "    return data\n",
    "\n",
    "# Preprocess captions\n",
    "data = text_preprocessing(data)\n",
    "captions = data['caption'].tolist()\n",
    "\n",
    "# 2. Tokenization and Data Preparation\n",
    "# =====================================\n",
    "\n",
    "# Initialize and fit tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max(len(caption.split()) for caption in captions)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "images = data['image'].unique().tolist()\n",
    "nimages = len(images)\n",
    "split_index = round(0.85 * nimages)\n",
    "train_images = images[:split_index]\n",
    "val_images = images[split_index:]\n",
    "\n",
    "train = data[data['image'].isin(train_images)]\n",
    "test = data[data['image'].isin(val_images)]\n",
    "\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# 3. Image Feature Extraction\n",
    "# ============================\n",
    "\n",
    "# Load DenseNet201 model for feature extraction\n",
    "base_model = DenseNet201()\n",
    "fe = Model(inputs=base_model.input, outputs=base_model.layers[-2].output)\n",
    "\n",
    "# Extract features for all images\n",
    "img_size = 224\n",
    "features = {}\n",
    "for image in tqdm(data['image'].unique().tolist()):\n",
    "    img = load_img(os.path.join(image_path, image), target_size=(img_size, img_size))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    feature = fe.predict(img, verbose=0)\n",
    "    features[image] = feature\n",
    "\n",
    "# 4. Data Generator\n",
    "# =================\n",
    "\n",
    "class CustomDataGenerator(Sequence):\n",
    "    def __init__(self, df, X_col, y_col, batch_size, directory, tokenizer, \n",
    "                 vocab_size, max_length, features, shuffle=True):\n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.directory = directory\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.features = features\n",
    "        self.shuffle = shuffle\n",
    "        self.n = len(self.df)\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size, :]\n",
    "        X1, X2, y = self.__get_data(batch)        \n",
    "        return (X1, X2), y\n",
    "    \n",
    "    def __get_data(self, batch):\n",
    "        X1, X2, y = list(), list(), list()\n",
    "        images = batch[self.X_col].tolist()\n",
    "           \n",
    "        for image in images:\n",
    "            feature = self.features[image][0]\n",
    "            captions = batch.loc[batch[self.X_col] == image, self.y_col].tolist()\n",
    "            \n",
    "            for caption in captions:\n",
    "                seq = self.tokenizer.texts_to_sequences([caption])[0]\n",
    "                \n",
    "                for i in range(1, len(seq)):\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=self.max_length)[0]\n",
    "                    out_seq = to_categorical([out_seq], num_classes=self.vocab_size)[0]\n",
    "                    \n",
    "                    X1.append(feature)\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            \n",
    "        return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "# 5. Model Architecture\n",
    "# ======================\n",
    "\n",
    "# Image input layer\n",
    "input1 = Input(shape=(1920,))\n",
    "# Text input layer\n",
    "input2 = Input(shape=(max_length,))\n",
    "\n",
    "# Image feature processing\n",
    "img_features = Dense(256, activation='relu')(input1)\n",
    "img_features_reshaped = Reshape((1, 256), input_shape=(256,))(img_features)\n",
    "\n",
    "# Text feature processing\n",
    "sentence_features = Embedding(vocab_size, 256, mask_zero=False)(input2)\n",
    "\n",
    "# Merge image and text features\n",
    "merged = concatenate([img_features_reshaped, sentence_features], axis=1)\n",
    "\n",
    "# LSTM processing\n",
    "sentence_features = LSTM(256)(merged)\n",
    "sentence_features = Dropout(0.5)(sentence_features)\n",
    "\n",
    "# Add image features to LSTM output (skip connection)\n",
    "x = add([sentence_features, img_features])\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(vocab_size, activation='softmax')(x)\n",
    "\n",
    "# Create and compile model\n",
    "caption_model = Model(inputs=[input1, input2], outputs=output)\n",
    "caption_model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "\n",
    "# Model summary\n",
    "caption_model.summary()\n",
    "\n",
    "# 6. Training the Model\n",
    "# ======================\n",
    "\n",
    "# Create data generators\n",
    "train_generator = CustomDataGenerator(\n",
    "    df=train, X_col='image', y_col='caption', batch_size=64,\n",
    "    directory=image_path, tokenizer=tokenizer, vocab_size=vocab_size,\n",
    "    max_length=max_length, features=features\n",
    ")\n",
    "\n",
    "validation_generator = CustomDataGenerator(\n",
    "    df=test, X_col='image', y_col='caption', batch_size=64,\n",
    "    directory=image_path, tokenizer=tokenizer, vocab_size=vocab_size,\n",
    "    max_length=max_length, features=features\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "model_name = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    model_name, monitor=\"val_loss\", mode=\"min\",\n",
    "    save_best_only=True, verbose=1\n",
    ")\n",
    "\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=5,\n",
    "    verbose=1, restore_best_weights=True\n",
    ")\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_loss', patience=3, verbose=1,\n",
    "    factor=0.2, min_lr=1e-8\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = caption_model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[checkpoint, earlystopping, learning_rate_reduction]\n",
    ")\n",
    "\n",
    "# 7. Visualization and Evaluation\n",
    "# ===============================\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 8. Caption Generation\n",
    "# =====================\n",
    "\n",
    "# Helper function to convert index to word\n",
    "def idx_to_word(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "# Function to generate caption for an image\n",
    "def predict_caption(model, image, tokenizer, max_length, features):\n",
    "    feature = features[image]\n",
    "    in_text = \"startseq\"\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        \n",
    "        y_pred = model.predict([feature, sequence], verbose=0)\n",
    "        y_pred = np.argmax(y_pred)\n",
    "        \n",
    "        word = idx_to_word(y_pred, tokenizer)\n",
    "        \n",
    "        if word is None:\n",
    "            break\n",
    "            \n",
    "        in_text += \" \" + word\n",
    "        \n",
    "        if word == 'endseq':\n",
    "            break\n",
    "            \n",
    "    return in_text\n",
    "\n",
    "# Generate captions for sample images\n",
    "samples = test.sample(15)\n",
    "samples.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for index, record in samples.iterrows():\n",
    "    img = load_img(os.path.join(image_path, record['image']), target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    \n",
    "    caption = predict_caption(caption_model, record['image'], tokenizer, max_length, features)\n",
    "    samples.loc[index, 'caption'] = caption\n",
    "\n",
    "# Display results\n",
    "display_images(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f079e8-36ce-4d83-a665-522b2325d8fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Expected 2 fields in line 22, saw 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./archive/flickr30k_images/results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Read CSV safely\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Rename to standard column names\u001b[39;00m\n\u001b[0;32m     31\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     34\u001b[0m })\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:288\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m    285\u001b[0m     indexnamerow \u001b[38;5;241m=\u001b[39m content[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    286\u001b[0m     content \u001b[38;5;241m=\u001b[39m content[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 288\u001b[0m alldata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows_to_cols(content)\n\u001b[0;32m    289\u001b[0m data, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclude_implicit_index(alldata)\n\u001b[0;32m    291\u001b[0m conv_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_data(data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:1063\u001b[0m, in \u001b[0;36mPythonParser._rows_to_cols\u001b[1;34m(self, content)\u001b[0m\n\u001b[0;32m   1057\u001b[0m             reason \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1058\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError could possibly be due to quotes being \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1059\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignored when a multi-char delimiter is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m             )\n\u001b[0;32m   1061\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m reason\n\u001b[1;32m-> 1063\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alert_malformed(msg, row_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# see gh-13320\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m zipped_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(lib\u001b[38;5;241m.\u001b[39mto_object_array(content, min_width\u001b[38;5;241m=\u001b[39mcol_len)\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:781\u001b[0m, in \u001b[0;36mPythonParser._alert_malformed\u001b[1;34m(self, msg, row_num)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03mAlert a user about a malformed row, depending on value of\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m`self.on_bad_lines` enum.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;124;03m    even though we 0-index internally.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_bad_lines \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBadLineHandleMethod\u001b[38;5;241m.\u001b[39mERROR:\n\u001b[1;32m--> 781\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(msg)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_bad_lines \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBadLineHandleMethod\u001b[38;5;241m.\u001b[39mWARN:\n\u001b[0;32m    783\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    785\u001b[0m         ParserWarning,\n\u001b[0;32m    786\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    787\u001b[0m     )\n",
      "\u001b[1;31mParserError\u001b[0m: Expected 2 fields in line 22, saw 4"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Dense, LSTM, Embedding, Dropout,\n",
    "                                     concatenate, Reshape, add)\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from textwrap import wrap\n",
    "import warnings\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==============================\n",
    "# CONFIGURATION\n",
    "# ==============================\n",
    "image_path = './archive/flickr30k_images'\n",
    "csv_path = './archive/flickr30k_images/results_cleaned.csv'\n",
    "img_size = 224\n",
    "batch_size = 64\n",
    "\n",
    "# ==============================\n",
    "# 1) Load and Prepare Dataset\n",
    "# ==============================\n",
    "data = pd.read_csv(csv_path, sep=\",\", engine='python')\n",
    "\n",
    "# Rename to match model expectations\n",
    "data = data.rename(columns={\n",
    "    'image_name': 'image',\n",
    "    'comment': 'caption'\n",
    "})\n",
    "if 'comment_number' in data.columns:\n",
    "    data = data.drop(columns=['comment_number'])\n",
    "\n",
    "print(\"Columns after rename:\", data.columns.tolist())\n",
    "assert 'image' in data.columns and 'caption' in data.columns, \\\n",
    "    \"CSV must have 'image' and 'caption' columns\"\n",
    "\n",
    "# ==============================\n",
    "# 2) Text Preprocessing\n",
    "# ==============================\n",
    "def text_preprocessing(df):\n",
    "    df = df.copy()\n",
    "    df['caption'] = df['caption'].astype(str).str.lower()\n",
    "    df['caption'] = df['caption'].str.replace('[^a-z\\s]', ' ', regex=True)\n",
    "    df['caption'] = df['caption'].str.replace('\\s+', ' ', regex=True).str.strip()\n",
    "    df['caption'] = df['caption'].apply(lambda s: \" \".join([w for w in s.split() if len(w) > 1]))\n",
    "    df['caption'] = df['caption'].apply(lambda s: f\"startseq {s} endseq\")\n",
    "    return df\n",
    "\n",
    "data = text_preprocessing(data)\n",
    "captions = data['caption'].tolist()\n",
    "print(\"Sample caption:\", captions[0])\n",
    "\n",
    "# ==============================\n",
    "# 3) Tokenization\n",
    "# ==============================\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max(len(c.split()) for c in captions)\n",
    "print(\"Vocab size:\", vocab_size, \"Max length:\", max_length)\n",
    "\n",
    "# ==============================\n",
    "# 4) Train / Validation Split\n",
    "# ==============================\n",
    "images = data['image'].unique().tolist()\n",
    "nimages = len(images)\n",
    "split_index = int(round(0.85 * nimages))\n",
    "train_images = images[:split_index]\n",
    "val_images = images[split_index:]\n",
    "\n",
    "train = data[data['image'].isin(train_images)].reset_index(drop=True)\n",
    "test = data[data['image'].isin(val_images)].reset_index(drop=True)\n",
    "print(f\"Train captions: {len(train)}, Validation captions: {len(test)}\")\n",
    "\n",
    "# ==============================\n",
    "# 5) Image Feature Extraction\n",
    "# ==============================\n",
    "base = DenseNet201(include_top=False, pooling='avg', weights='imagenet',\n",
    "                   input_shape=(img_size, img_size, 3))\n",
    "fe = Model(inputs=base.input, outputs=base.output)\n",
    "feature_dim = fe.output_shape[1]\n",
    "print(\"Feature dimension:\", feature_dim)\n",
    "\n",
    "# Extract image features\n",
    "features = {}\n",
    "for image in tqdm(data['image'].unique().tolist(), desc=\"Extracting features\"):\n",
    "    img_file = os.path.join(image_path, image)\n",
    "    if not os.path.exists(img_file):\n",
    "        print(f\"⚠️ Warning: Missing image {img_file}\")\n",
    "        continue\n",
    "    img = load_img(img_file, target_size=(img_size, img_size))\n",
    "    arr = img_to_array(img)\n",
    "    arr = preprocess_input(arr)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    feat = fe.predict(arr, verbose=0)\n",
    "    features[image] = feat.squeeze()\n",
    "\n",
    "print(f\"✅ Extracted features for {len(features)} images.\")\n",
    "\n",
    "# ==============================\n",
    "# 6) Custom Data Generator\n",
    "# ==============================\n",
    "class CustomDataGenerator(Sequence):\n",
    "    def __init__(self, df, X_col, y_col, batch_size, tokenizer, vocab_size, max_length, features, shuffle=True):\n",
    "        self.df = df.copy()\n",
    "        self.X_col = X_col\n",
    "        self.y_col = y_col\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.features = features\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.df) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_df = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X1, X2, y = self.__get_data(batch_df)\n",
    "        return [X1, X2], y\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        X1, X2, y = [], [], []\n",
    "        for _, row in batch.iterrows():\n",
    "            img_name = row[self.X_col]\n",
    "            caption = row[self.y_col]\n",
    "            if img_name not in self.features:\n",
    "                continue\n",
    "            img_feat = self.features[img_name]\n",
    "            seq = self.tokenizer.texts_to_sequences([caption])[0]\n",
    "            for i in range(1, len(seq)):\n",
    "                in_seq, out_seq = seq[:i], seq[i]\n",
    "                in_seq = pad_sequences([in_seq], maxlen=self.max_length)[0]\n",
    "                out_seq = to_categorical([out_seq], num_classes=self.vocab_size)[0]\n",
    "                X1.append(img_feat)\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "        if len(X1) == 0:\n",
    "            return np.zeros((0, feature_dim)), np.zeros((0, self.max_length)), np.zeros((0, self.vocab_size))\n",
    "        return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "# ==============================\n",
    "# 7) Model Architecture\n",
    "# ==============================\n",
    "input1 = Input(shape=(feature_dim,), name='image_input')\n",
    "input2 = Input(shape=(max_length,), name='seq_input')\n",
    "\n",
    "img_dense = Dense(256, activation='relu')(input1)\n",
    "img_reshaped = Reshape((1, 256))(img_dense)\n",
    "\n",
    "emb = Embedding(input_dim=vocab_size, output_dim=256, mask_zero=True)(input2)\n",
    "merged = concatenate([img_reshaped, emb], axis=1)\n",
    "\n",
    "lstm = LSTM(256)(merged)\n",
    "lstm = Dropout(0.5)(lstm)\n",
    "\n",
    "# Skip connection\n",
    "skip = Dense(256, activation='relu')(img_dense)\n",
    "x = add([lstm, skip])\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(vocab_size, activation='softmax')(x)\n",
    "\n",
    "caption_model = Model(inputs=[input1, input2], outputs=output)\n",
    "caption_model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "caption_model.summary()\n",
    "\n",
    "# ==============================\n",
    "# 8) Training Setup\n",
    "# ==============================\n",
    "train_gen = CustomDataGenerator(train, 'image', 'caption', batch_size,\n",
    "                                tokenizer, vocab_size, max_length, features, shuffle=True)\n",
    "val_gen = CustomDataGenerator(test, 'image', 'caption', batch_size,\n",
    "                              tokenizer, vocab_size, max_length, features, shuffle=False)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"caption_model.h5\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, verbose=1, min_lr=1e-8)\n",
    "]\n",
    "\n",
    "history = caption_model.fit(\n",
    "    train_gen,\n",
    "    epochs=50,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 9) Plot Training Loss\n",
    "# ==============================\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ==============================\n",
    "# 10) Caption Generation\n",
    "# ==============================\n",
    "def idx_to_word(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "def predict_caption(model, img_name, tokenizer, max_length, features):\n",
    "    if img_name not in features:\n",
    "        return \"\"\n",
    "    in_text = \"startseq\"\n",
    "    for _ in range(max_length):\n",
    "        seq = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        seq = pad_sequences([seq], maxlen=max_length)\n",
    "        img_feat = features[img_name].reshape((1, feature_dim))\n",
    "        yhat = model.predict([img_feat, seq], verbose=0)\n",
    "        yint = np.argmax(yhat)\n",
    "        word = idx_to_word(yint, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += \" \" + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text\n",
    "\n",
    "# Generate captions for random validation images\n",
    "samples = test.sample(10).reset_index(drop=True)\n",
    "for i, row in samples.iterrows():\n",
    "    pred = predict_caption(caption_model, row['image'], tokenizer, max_length, features)\n",
    "    print(f\"\\nImage: {row['image']}\\nGenerated Caption: {pred}\\nActual Caption: {row['caption']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da04ccc8-b69a-4fbe-bf16-89ffbe323534",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Expected 2 fields in line 22, saw 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./archive/flickr30k_images/results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Read CSV safely\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Rename to standard column names\u001b[39;00m\n\u001b[0;32m     31\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     34\u001b[0m })\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:288\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m    285\u001b[0m     indexnamerow \u001b[38;5;241m=\u001b[39m content[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    286\u001b[0m     content \u001b[38;5;241m=\u001b[39m content[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 288\u001b[0m alldata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rows_to_cols(content)\n\u001b[0;32m    289\u001b[0m data, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclude_implicit_index(alldata)\n\u001b[0;32m    291\u001b[0m conv_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_data(data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:1063\u001b[0m, in \u001b[0;36mPythonParser._rows_to_cols\u001b[1;34m(self, content)\u001b[0m\n\u001b[0;32m   1057\u001b[0m             reason \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1058\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError could possibly be due to quotes being \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1059\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignored when a multi-char delimiter is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m             )\n\u001b[0;32m   1061\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m reason\n\u001b[1;32m-> 1063\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alert_malformed(msg, row_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# see gh-13320\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m zipped_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(lib\u001b[38;5;241m.\u001b[39mto_object_array(content, min_width\u001b[38;5;241m=\u001b[39mcol_len)\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:781\u001b[0m, in \u001b[0;36mPythonParser._alert_malformed\u001b[1;34m(self, msg, row_num)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03mAlert a user about a malformed row, depending on value of\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03m`self.on_bad_lines` enum.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;124;03m    even though we 0-index internally.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_bad_lines \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBadLineHandleMethod\u001b[38;5;241m.\u001b[39mERROR:\n\u001b[1;32m--> 781\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(msg)\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_bad_lines \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBadLineHandleMethod\u001b[38;5;241m.\u001b[39mWARN:\n\u001b[0;32m    783\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    785\u001b[0m         ParserWarning,\n\u001b[0;32m    786\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    787\u001b[0m     )\n",
      "\u001b[1;31mParserError\u001b[0m: Expected 2 fields in line 22, saw 4"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Image Caption Generator (Fixed Full Version)\n",
    "# =============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# =====================================================\n",
    "# 1) Data Loading and Preprocessing\n",
    "# =====================================================\n",
    "\n",
    "image_path = './archive/flickr30k_images'\n",
    "csv_path = './archive/flickr30k_images/results.csv'\n",
    "\n",
    "# Read CSV safely\n",
    "data = pd.read_csv(csv_path, sep=\",\", engine='python')\n",
    "\n",
    "# Rename to standard column names\n",
    "data = data.rename(columns={\n",
    "    'image_name': 'image',\n",
    "    'comment': 'caption'\n",
    "})\n",
    "if 'comment_number' in data.columns:\n",
    "    data = data.drop(columns=['comment_number'])\n",
    "\n",
    "print(\"Columns after rename:\", data.columns.tolist())\n",
    "assert 'image' in data.columns and 'caption' in data.columns, \"CSV must have 'image' and 'caption' columns\"\n",
    "\n",
    "# =====================================================\n",
    "# 2) Text Preprocessing\n",
    "# =====================================================\n",
    "\n",
    "def text_preprocessing(df):\n",
    "    df['caption'] = df['caption'].apply(lambda x: x.strip().lower())\n",
    "    df['caption'] = df['caption'].apply(lambda x: 'startseq ' + x + ' endseq')\n",
    "    return df\n",
    "\n",
    "data = text_preprocessing(data)\n",
    "print(\"Sample Caption:\", data['caption'].iloc[0])\n",
    "\n",
    "# =====================================================\n",
    "# 3) Feature Extraction from Images (InceptionV3)\n",
    "# =====================================================\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet')\n",
    "model_new = Model(base_model.input, base_model.layers[-2].output)\n",
    "\n",
    "# Extract image features if not already cached\n",
    "feature_path = './features.npy'\n",
    "\n",
    "if os.path.exists(feature_path):\n",
    "    features = np.load(feature_path, allow_pickle=True).item()\n",
    "else:\n",
    "    features = {}\n",
    "    for img_name in tqdm(os.listdir(image_path)[:2000]):  # limit for test\n",
    "        img_path = os.path.join(image_path, img_name)\n",
    "        img = image.load_img(img_path, target_size=(299, 299))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = tf.keras.applications.inception_v3.preprocess_input(img_array)\n",
    "        feature = model_new.predict(img_array)\n",
    "        features[img_name] = feature.flatten()\n",
    "    np.save(feature_path, features)\n",
    "\n",
    "print(\"Total images processed:\", len(features))\n",
    "\n",
    "# =====================================================\n",
    "# 4) Tokenization\n",
    "# =====================================================\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['caption'])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Vocab Size:\", vocab_size)\n",
    "\n",
    "# =====================================================\n",
    "# 5) Train-Test Split\n",
    "# =====================================================\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# =====================================================\n",
    "# 6) Data Generator Class (Fixed)\n",
    "# =====================================================\n",
    "\n",
    "class CustomDataGenerator(Sequence):\n",
    "    def __init__(self, df, img_col, cap_col, batch_size, tokenizer, vocab_size, max_length, features, shuffle=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_col = img_col\n",
    "        self.cap_col = cap_col\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.features = features\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(df))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        X1, X2, y = self.__data_generation(batch_indexes)\n",
    "        return (X1, X2), y  # ✅ FIXED (tuple, not list)\n",
    "\n",
    "    def __data_generation(self, batch_indexes):\n",
    "        X1, X2, y = list(), list(), list()\n",
    "\n",
    "        for i in batch_indexes:\n",
    "            row = self.df.iloc[i]\n",
    "            img_id = row[self.img_col]\n",
    "            caption = row[self.cap_col]\n",
    "            if img_id not in self.features:\n",
    "                continue\n",
    "\n",
    "            seq = self.tokenizer.texts_to_sequences([caption])[0]\n",
    "            for j in range(1, len(seq)):\n",
    "                in_seq, out_seq = seq[:j], seq[j]\n",
    "                in_seq = pad_sequences([in_seq], maxlen=self.max_length)[0]\n",
    "                out_seq = to_categorical([out_seq], num_classes=self.vocab_size)[0]\n",
    "                X1.append(self.features[img_id])\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "\n",
    "        return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "# =====================================================\n",
    "# 7) Model Definition\n",
    "# =====================================================\n",
    "\n",
    "max_length = 35  # you can adjust based on captions\n",
    "\n",
    "inputs1 = Input(shape=(2048,))\n",
    "fe1 = Dropout(0.5)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "inputs2 = Input(shape=(max_length,))\n",
    "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.5)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "caption_model = tf.keras.models.Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "caption_model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "caption_model.summary()\n",
    "\n",
    "# =====================================================\n",
    "# 8) Training\n",
    "# =====================================================\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_gen = CustomDataGenerator(train, 'image', 'caption', batch_size,\n",
    "                                tokenizer, vocab_size, max_length, features, shuffle=True)\n",
    "val_gen = CustomDataGenerator(test, 'image', 'caption', batch_size,\n",
    "                              tokenizer, vocab_size, max_length, features, shuffle=False)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"caption_model.h5\", monitor=\"val_loss\", save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, verbose=1, min_lr=1e-8)\n",
    "]\n",
    "\n",
    "history = caption_model.fit(\n",
    "    train_gen,\n",
    "    epochs=50,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# 9) Plot Training Loss\n",
    "# =====================================================\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d48dac-12f8-4ef5-bd0c-49bd840ca121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
